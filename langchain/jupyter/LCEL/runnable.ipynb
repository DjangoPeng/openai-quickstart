{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06432a41-540a-4a55-b3fa-8665032e6127",
   "metadata": {},
   "source": [
    "## Runnable Interface ä»‹ç»ä¸ä½¿ç”¨\n",
    "\n",
    "ä¸ºäº†å°½å¯èƒ½ç®€åŒ–åˆ›å»ºè‡ªå®šä¹‰é“¾çš„è¿‡ç¨‹ï¼ŒLangchain å®ç°äº†ä¸€ä¸ª **[Runnable](https://api.python.langchain.com/en/stable/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable)** åè®®ã€‚\n",
    "\n",
    "è®¸å¤š LangChain ç»„ä»¶éƒ½å®ç°äº† Runnable åè®®ï¼ŒåŒ…æ‹¬ chat models, LLMs, output parsers, retrievers, prompt templatesç­‰ç­‰ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰å‡ ä¸ªç”¨äºå¤„ç†å¯è¿è¡Œå¯¹è±¡çš„[æœ‰ç”¨åŸè¯­](https://python.langchain.com/v0.1/docs/expression_language/primitives/)ã€‚\n",
    "\n",
    "Runnable æ˜¯ä¸€ä¸ªæ ‡å‡†æ¥å£ï¼ŒåŒ…æ‹¬ï¼š\n",
    "\n",
    "- streamï¼šæµå¼è¿”å›ç”Ÿæˆå†…å®¹ï¼ˆchunkï¼‰\n",
    "- invokeï¼šå¯¹è¾“å…¥è°ƒç”¨è¯¥é“¾\n",
    "- batchï¼šå¯¹è¾“å…¥åˆ—è¡¨è°ƒç”¨è¯¥é“¾\n",
    "\n",
    "ä¸åŒç»„ä»¶çš„è¾“å…¥å’Œè¾“å‡ºç±»å‹æœ‰æ‰€å·®å¼‚:\n",
    "\n",
    "| ç»„ä»¶    | è¾“å…¥ç±»å‹                                           | è¾“å‡ºç±»å‹           |\n",
    "| ------------ | ----------------------------------------------------- | --------------------- |\n",
    "| Prompt       | Dictionary                                            | PromptValue           |\n",
    "| ChatModel    | Single string, list of chat messages or a PromptValue | ChatMessage           |\n",
    "| LLM          | Single string, list of chat messages or a PromptValue | String                |\n",
    "| OutputParser | The output of an LLM or ChatModel                     | Depends on the parser |\n",
    "| Retriever    | Single string                                         | List of Documents     |\n",
    "| Tool         | Single string or dictionary, depending on the tool    | Depends on the tool   |\n",
    "\n",
    "\n",
    "æ‰€æœ‰ Runnable å¯¹è±¡éƒ½æ˜¾å¼æè¿°è¾“å…¥å’Œè¾“å‡º Schemaï¼Œä»¥æ£€æŸ¥è¾“å…¥å’Œè¾“å‡ºæ ¼å¼ï¼š\n",
    "\n",
    "- input_schemaï¼šä»Runnableçš„ç»“æ„è‡ªåŠ¨ç”Ÿæˆçš„è¾“å…¥Pydanticæ¨¡å‹\n",
    "- output_schemaï¼šä»Runnableçš„ç»“æ„è‡ªåŠ¨ç”Ÿæˆçš„è¾“å‡ºPydanticæ¨¡å‹ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03529a6-80f3-425a-988c-0f1b0dd17d3c",
   "metadata": {},
   "source": [
    "### Input Schema\n",
    "\n",
    "ä¸ºäº†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ï¼Œä¸‹é¢æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¶…çº§ç®€å•çš„PromptTemplate + ChatModelé“¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a3f4fd-e4dc-45ac-a9cf-a36b5791aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "prompt = ChatPromptTemplate.from_template(\"è®²ä¸ªå…³äº {topic} çš„ç¬‘è¯å§\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bb871-a240-429b-b622-23a65f5b4af2",
   "metadata": {},
   "source": [
    "#### schema æ–¹æ³•\n",
    "\n",
    "ä¸€ä¸ªæè¿° Runnable æ¥å—çš„è¾“å…¥çš„è¯´æ˜ã€‚è¿™æ˜¯æ ¹æ®ä»»ä½• Runnable ç»“æ„åŠ¨æ€ç”Ÿæˆçš„ Pydantic æ¨¡å‹ã€‚æ‚¨å¯ä»¥è°ƒç”¨ .schema() æ¥è·å– `JSONSchema` è¡¨ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a39360-11de-407f-92bc-c372a5a8efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Chain çš„è¾“å…¥ç±»å‹\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8fc874-0a36-404a-a627-72dfd50d719b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Prompt çš„è¾“å…¥ç±»å‹ï¼ˆChainçš„è¾“å…¥ä» Prompt å¼€å§‹ï¼Œå› æ­¤è¾“å…¥ç±»å‹ä¸€è‡´ï¼‰\n",
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6077c1-4add-4d0a-a81b-b4b8dba1d950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to raw_output.\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            raw_output=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'raw_output': {'title': 'Raw Output'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Model çš„è¾“å…¥ç±»å‹\n",
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7914531-4e20-4d62-b95d-72930ad6f3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d4c11-31b5-4edc-9a4b-611644aea24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db2bc6e0-0e6e-497d-bde3-3f24fa9ded77",
   "metadata": {},
   "source": [
    "### Output Schema\n",
    "\n",
    "è¾“å‡ºç±»å‹ä»ç„¶å¯ä»¥è°ƒç”¨ .schema() æ¥è·å–å…¶ `JSONSchema` è¡¨ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc07c2a-f9fb-4013-a7c3-6a74c2cb3754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to raw_output.\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            raw_output=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'raw_output': {'title': 'Raw Output'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Chain çš„è¾“å‡ºç±»å‹\n",
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc971bb2-8279-4e38-a539-54cc41a5e4a5",
   "metadata": {},
   "source": [
    "### Stream\n",
    "\n",
    "ä½¿ç”¨ .stream() æ–¹æ³•æŸ¥çœ‹ï¼ˆåŒæ­¥ï¼‰æµå¼è¾“å‡ºç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cebbeb5-72e0-4606-8383-fa7efa6465bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æŠŠé”™è¯¯å½’å’äºç”¨æˆ·å‘¢ï¼Ÿå› ä¸ºä»–ä»¬ä»æ¥ä¸ä¼šçŠ¯é”™ï¼Œåªä¼šå†™bugï¼"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"ç¨‹åºå‘˜\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444adacc-ee61-4c41-a2a0-c7a6278a6dea",
   "metadata": {},
   "source": [
    "### Invoke\n",
    "ä½¿ç”¨ .invoke() æ–¹æ³•å•æ¬¡ï¼ˆåŒæ­¥ï¼‰è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b68201-63a0-48f0-ae40-a835fb889c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯åœ¨æ·±å¤œå·¥ä½œï¼Ÿå› ä¸ºä»–ä»¬å–œæ¬¢åœ¨é»‘æš—ä¸­æ•²å‡»é”®ç›˜ï¼Œä»¿ä½›æ˜¯åœ¨é»‘å®¢å¸å›½ä¸­ï¼', response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 22, 'total_tokens': 71}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5c67061f-e76b-4d1b-9ee6-146bedf853bd-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"ç¨‹åºå‘˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f0ec6-f2d6-4b75-ae6c-6e5e685a326b",
   "metadata": {},
   "source": [
    "### Batch\n",
    "ä½¿ç”¨ .batch() æ–¹æ³•ï¼ˆåŒæ­¥ï¼‰æ‰¹é‡è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867e73cd-e59e-47d3-8284-d0b97eddc5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æ‡’æƒ°ï¼Ÿå› ä¸ºä»–ä»¬æ€»æ˜¯åœ¨åŠªåŠ›å‡å°‘ä»£ç è¡Œæ•°ï¼Œä»¥ä¾¿å°‘å†™ä¸€ç‚¹ã€‚', response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 22, 'total_tokens': 61}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8be03fd1-3bfb-4601-b592-8b63edba95d9-0'),\n",
       " AIMessage(content='ä¸ºä»€ä¹ˆäº§å“ç»ç†æ€»æ˜¯åœ¨åŠ ç­ï¼Ÿ\\nå› ä¸ºä»–ä»¬æ€»æ˜¯åœ¨è¿½æ±‚å®Œç¾ï¼Œè€Œå®Œç¾æ˜¯æ°¸è¿œæ— æ³•å®ç°çš„ï¼', response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 21, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-84198e02-10c1-4aa7-9b38-113df49e57d3-0'),\n",
       " AIMessage(content='æµ‹è¯•ç»ç†åœ¨å…¬å¸é‡Œå¼€äº†ä¸ªä¼šï¼Œä»–è¯´ï¼šâ€œæˆ‘ä»¬çš„æµ‹è¯•å·¥ä½œå¿…é¡»å°½å¯èƒ½å®Œç¾ï¼Œä¸€å®šè¦åšåˆ°ç™¾åˆ†ä¹‹ç™¾çš„å‡†ç¡®ç‡ï¼â€\\n\\nä¸€åå‘˜å·¥é—®é“ï¼šâ€œé‚£æˆ‘ä»¬æ€ä¹ˆçŸ¥é“æˆ‘ä»¬çš„æµ‹è¯•å·¥ä½œåšçš„å¤Ÿå¥½å‘¢ï¼Ÿâ€\\n\\næµ‹è¯•ç»ç†ç­”é“ï¼šâ€œå½“ä½ ä»¬æµ‹è¯•å®Œä¸€ä¸ªè½¯ä»¶ï¼Œç”¨æˆ·åé¦ˆè¯´â€˜è¿™ä¸ªè½¯ä»¶ç®€ç›´å°±æ˜¯ç¥ä½œï¼â€™ï¼Œé‚£å°±è¯´æ˜æˆ‘ä»¬çš„å·¥ä½œåšçš„å¤Ÿå¥½äº†ï¼â€', response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 21, 'total_tokens': 150}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-997d6c02-fcfe-4664-95de-356d0a4566be-0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"ç¨‹åºå‘˜\"}, {\"topic\": \"äº§å“ç»ç†\"}, {\"topic\": \"æµ‹è¯•ç»ç†\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c55997-250a-4603-985b-674f33a39bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = chain.batch([{\"topic\": \"ç¨‹åºå‘˜\"}, {\"topic\": \"äº§å“ç»ç†\"}, {\"topic\": \"æµ‹è¯•ç»ç†\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7648e692-7581-4fc0-a453-52cb0e9484f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬‘è¯0:\n",
      "\n",
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯è§‰å¾—å†·ï¼Ÿ\n",
      "å› ä¸ºä»–ä»¬æ€»æ˜¯åœ¨byteã€‚\n",
      "\n",
      "\n",
      "ç¬‘è¯1:\n",
      "\n",
      "ä¸ºä»€ä¹ˆäº§å“ç»ç†æ€»æ˜¯å¸¦ç€å°ºå­ï¼Ÿ\n",
      "å› ä¸ºä»–ä»¬è¦æ—¶åˆ»ä¿æŒäº§å“çš„å°ºåº¦ã€‚\n",
      "\n",
      "\n",
      "ç¬‘è¯2:\n",
      "\n",
      "ä¸ºä»€ä¹ˆæµ‹è¯•ç»ç†æ€»æ˜¯åœ¨å‘¨äº”ä¸‹åˆå‘å¸ƒbugä¿®å¤çš„ä»»åŠ¡ï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–ä»¬çŸ¥é“ç¨‹åºå‘˜ä»¬å‘¨æœ«ä¸ä¼šå»å¼€å‘æ–°åŠŸèƒ½ï¼Œåªä¼šä¸“å¿ƒä¿®bugï¼ğŸ˜„\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ StrOutputParser æ¥å¤„ç† Batch æ‰¹é‡è¾“å‡º\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "for idx, m in enumerate(messages):\n",
    "    print(f\"ç¬‘è¯{idx}:\\n\")\n",
    "    print(output_parser.invoke(m))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d9980-0d5a-4fe7-9a5a-5c6a7fbdfafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8436e-a647-4562-a2e2-efade07fa090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e2800-354e-4575-9f1c-d2d2a275de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0bfd2f7-586a-46f8-846a-2f0ea99be1d4",
   "metadata": {},
   "source": [
    "## å¼‚æ­¥æ“ä½œ\n",
    "\n",
    "è¿™äº›æ–¹æ³•ä¹Ÿæœ‰ç›¸åº”çš„å¼‚æ­¥æ–¹æ³•ï¼Œåº”ä¸ `asyncio` çš„ `await` è¯­æ³•ä¸€èµ·ä½¿ç”¨ä»¥è¿›è¡Œå¹¶å‘æ“ä½œï¼š\n",
    "\n",
    "- astreamï¼šå¼‚æ­¥åœ°æµå¼è¿”å›ç”Ÿæˆå†…å®¹ï¼ˆchunkï¼‰\n",
    "- ainvokeï¼šå¼‚æ­¥åœ°å¯¹è¾“å…¥è°ƒç”¨è¯¥é“¾\n",
    "- abatchï¼šå¼‚æ­¥åœ°å¯¹è¾“å…¥åˆ—è¡¨è°ƒç”¨è¯¥é“¾\n",
    "- astream_log: åœ¨å‘ç”Ÿæ—¶ä¼šè¿”å›ä¸­é—´æ­¥éª¤ï¼Œå¹¶ä¸”æœ€ç»ˆè¿”å›ç»“æœä¹‹å¤–ã€‚\n",
    "- astream_events: beta æµå¼ä¼ è¾“äº‹ä»¶ï¼Œåœ¨ langchain-core 0.1.14 ä¸­å¼•å…¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2d21e-17c7-42e4-905a-9c7e924b44fc",
   "metadata": {},
   "source": [
    "### Async Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cbd50d5-8706-4105-8191-41278004c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯å–œæ¬¢ç”¨å’–å•¡å› æ¥æç¥å·¥ä½œï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–ä»¬è§‰å¾—ç”¨ Java æ¥å†™ä»£ç ï¼Œä¸€æ¯å’–å•¡æ˜¯å¿…é¡»çš„ï¼"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"topic\": \"ç¨‹åºå‘˜\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718496f-ce02-4465-8757-3f6d6e48c063",
   "metadata": {},
   "source": [
    "### Async Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1fceaf-15aa-44f1-9f31-81d82d64f43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯å¸¦ç€ç”µè„‘å»å•æ‰€ï¼Ÿ\\nå› ä¸ºä»–ä»¬è§‰å¾—åœ¨é‚£é‡Œæ‰èƒ½çœŸæ­£çš„è§£å†³é—®é¢˜ï¼ğŸ˜‚', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 22, 'total_tokens': 67}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f20841ef-c00f-4cbf-83eb-1d5413d21134-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke({\"topic\": \"ç¨‹åºå‘˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88f80e-0b9d-49b4-a44d-9f26f9da2819",
   "metadata": {},
   "source": [
    "### Async Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f6493d-0b88-4584-89ac-63b60a21fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æ··æ·†â€œå·¥ä½œâ€å’Œâ€œç”Ÿæ´»â€ï¼Ÿ\\n\\nå› ä¸ºä»–ä»¬æ€»æ˜¯æŠŠä»£ç å½“æˆè‡ªå·±çš„ç”Ÿæ´»ï¼Œè€ŒæŠŠç”Ÿæ´»å½“æˆè‡ªå·±çš„ä»£ç ã€‚', response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 22, 'total_tokens': 75}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5210bade-2763-43c6-8695-a9edcc878eca-0'),\n",
       " AIMessage(content='ä¸ºä»€ä¹ˆäº§å“ç»ç†æ€»æ˜¯è¿Ÿåˆ°ï¼Ÿ\\n\\nå› ä¸ºä»–ä»¬æ€»æ˜¯åœ¨ç­‰ç”¨æˆ·åé¦ˆï¼', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 21, 'total_tokens': 47}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-db28a164-d641-4da9-bba0-3725f4b2f6bf-0'),\n",
       " AIMessage(content='ä¸ºä»€ä¹ˆæµ‹è¯•ç»ç†æ€»æ˜¯å–œæ¬¢å»é’“é±¼ï¼Ÿ\\n\\nå› ä¸ºä»–ä»¬å–œæ¬¢æµ‹è¯•æ°´åŸŸçš„æ·±åº¦ï¼', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 21, 'total_tokens': 58}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-239c2e42-8302-401a-ade8-31234f0b9af0-0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch([{\"topic\": \"ç¨‹åºå‘˜\"}, {\"topic\": \"äº§å“ç»ç†\"}, {\"topic\": \"æµ‹è¯•ç»ç†\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e40e27-a304-45ae-bc58-1d759e823671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
